import os
import json
import re
from typing import List, Dict, Any
import streamlit as st
from tavily import TavilyClient
import datetime

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å­¦æœ¯è®ºæ–‡è¯„å®¡ç³»ç»Ÿ",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# åŠ è½½æœ¬åœ°CSSæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    local_css("style.css")
except:
    # é»˜è®¤æ ·å¼
    st.markdown("""
    <style>
    /* ä¸»å®¹å™¨æ ·å¼ */
    .stApp {
        background-color: #f8f9fa;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .stMarkdown h1 {
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 0.3em;
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    .stTextInput>div>div>input {
        background-color: #ffffff;
        border-radius: 8px;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton>button {
        background-color: #3498db;
        color: white;
        border-radius: 8px;
        padding: 0.5em 1em;
        border: none;
        transition: all 0.3s;
    }
    
    .stButton>button:hover {
        background-color: #2980b9;
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    
    /* æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    
    .stTabs [data-baseweb="tab"] {
        background: #e8f4fc;
        border-radius: 8px 8px 0 0;
        padding: 10px 20px;
        transition: all 0.3s;
    }
    
    .stTabs [aria-selected="true"] {
        background: #3498db;
        color: white;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    [data-testid="stSidebar"] {
        background: linear-gradient(145deg, #2c3e50, #34495e);
        color: white;
    }
    
    [data-testid="stSidebar"] .stMarkdown h2 {
        color: #ecf0f1;
        border-bottom: 1px solid #7f8c8d;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .stExpander {
        background: white;
        border-radius: 10px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.05);
        margin-bottom: 1em;
    }
    
    /* çŠ¶æ€æ¶ˆæ¯æ ·å¼ */
    [data-testid="stStatusWidget"] {
        border-radius: 10px;
    }
    
    /* å“åº”å¼è°ƒæ•´ */
    @media (max-width: 768px) {
        .stTextInput>div>div>input {
            font-size: 14px;
        }
    }
    
    /* å¼•ç”¨æ ·å¼ */
    blockquote {
        border-left: 4px solid #3498db;
        padding-left: 1em;
        color: #7f8c8d;
        font-style: italic;
    }
    </style>
    """, unsafe_allow_html=True)

class AcademicPaperReviewer:
    def __init__(self, tavily_api_key: str, deepseek_api_key: str, 
                 deepseek_api_base: str = "https://api.deepseek.com"):
        self.tavily_client = TavilyClient(api_key=tavily_api_key)
        self.deepseek_api_key = deepseek_api_key
        self.deepseek_api_base = deepseek_api_base
        self.deepseek_model = "deepseek-chat"
        self.professional_domains = [
            "agupubs.onlinelibrary.wiley.com",
            "journals.ametsoc.org",
            "rmets.onlinelibrary.wiley.com",
            "wmo.int",
            "nasa.gov",
            "arxiv.org",
            "springer.com",
            "nature.com",
            "researchgate.net",
            "science.org",
            "pnas.org",
            "jstor.org"
        ]
        
    def search_with_tavily(self, query: str, max_results: int = 15) -> List[Dict]:
        """
        ä½¿ç”¨Tavilyå®˜æ–¹å®¢æˆ·ç«¯è¿›è¡Œä¸“ä¸šå­¦æœ¯æœç´¢
        """
        st.info(f"æ­£åœ¨ä½¿ç”¨Tavilyæœç´¢å­¦æœ¯ä¿¡æ¯: {query}")
        
        try:
            response = self.tavily_client.search(
                query=query,
                search_depth="advanced",
                include_answer=False,
                include_raw_content=False,
                max_results=max_results,
                include_domains=self.professional_domains,
                exclude_domains=["wikipedia.org"]
            )
            
            results = []
            for result in response.get("results", []):
                if any(domain in result.get("url", "") for domain in self.professional_domains):
                    results.append({
                        "title": result.get("title", ""),
                        "snippet": result.get("content", ""),
                        "url": result.get("url", ""),
                        "published_date": result.get("published_date", ""),
                        "authors": result.get("authors", []),
                        "score": result.get("score", 0)
                    })
            
            if results:
                results.sort(key=lambda x: x["score"], reverse=True)
                st.success(f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœã€‚")
                return results[:max_results]
            
            st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æœ")
            return []
            
        except Exception as e:
            st.error(f"Tavilyæœç´¢å‡ºé”™: {e}")
            return []

    def process_with_multiple_experts(self, combined_text: str, topic: str) -> Dict[str, str]:
        """
        å¤šä¸“å®¶åä½œå¤„ç†æ–‡æœ¬
        """
        expert_prompts = {
            "æ€»ç»“ä¸“å®¶": """è¯·æ ¹æ®ä»¥ä¸‹æœç´¢ç»“æœï¼Œæ’°å†™å…³äºä¸»é¢˜"{topic}"çš„æ–‡çŒ®ç»¼è¿°ã€‚
            æ–‡ç« åº”åŒ…å«å…³é”®äº‹å®ã€èƒŒæ™¯ä¿¡æ¯å’Œç›¸å…³æ¦‚å¿µã€‚
            è¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€æµç•…ï¼Œå¹¶æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„ä¿¡æ¯ã€‚
            è¯·ä½¿ç”¨ä¸­æ–‡æ’°å†™ï¼Œä¸¥æ ¼éµå¾ªWMOæœ¯è¯­æ ‡å‡†ã€‚""",
            "é—®é¢˜ç”Ÿæˆä¸“å®¶": """è¯·æ ¹æ®ä»¥ä¸‹å…³äºä¸»é¢˜"{topic}"çš„æœç´¢ç»“æœæ‘˜è¦ï¼Œæå‡ºç›¸å…³çš„ç ”ç©¶é—®é¢˜ã€‚
            è¯·ä»¥åˆ—è¡¨å½¢å¼åˆ—å‡ºè¿™äº›é—®é¢˜ï¼Œå¹¶æ ‡æ³¨æ¨èåˆ†ææ–¹æ³•ã€‚
            è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚""",
            "å…³é”®æ¦‚å¿µä¸“å®¶": """è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–ä¸ä¸»é¢˜"{topic}"ç›¸å…³çš„å…³é”®æ¦‚å¿µå’Œæœ¯è¯­ã€‚
            è¯·ç¡®ä¿ä½¿ç”¨WMOæ ‡å‡†æœ¯è¯­ã€‚
            è¯·ä»¥åˆ—è¡¨å½¢å¼åˆ—å‡ºè¿™äº›æ¦‚å¿µã€‚""",
            "æœªæ¥æ–¹å‘ä¸“å®¶": """è¯·æ ¹æ®ä»¥ä¸‹å…³äºä¸»é¢˜"{topic}"çš„æœç´¢ç»“æœæ‘˜è¦ï¼Œæå‡ºå¯èƒ½çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚
            è¯·ä»¥åˆ—è¡¨å½¢å¼åˆ—å‡ºè¿™äº›å»ºè®®ã€‚
            è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚"""
        }
        
        expert_outputs = {}
        progress_bar = st.progress(0)
        total_experts = len(expert_prompts)
        
        for i, (expert_name, prompt_template) in enumerate(expert_prompts.items()):
            progress_bar.progress((i + 1) / total_experts, text=f"{expert_name}æ­£åœ¨å¤„ç†...")
            prompt = prompt_template.format(topic=topic)
            output = self._call_deepseek(prompt, combined_text)
            expert_outputs[expert_name] = output
        
        progress_bar.empty()
        return expert_outputs

    def format_academic_output(self, expert_results: Dict[str, str], references: List[Dict]) -> str:
        """
        æŒ‰ç…§knowledge_stormé£æ ¼æ ¼å¼åŒ–è¾“å‡º
        """
        first_expert_output = list(expert_results.values())[0]
        title_line = first_expert_output.splitlines()[0] if first_expert_output else "æ–‡çŒ®ç»¼è¿°"
        formatted = f"# {title_line}\n\n"
        
        # æ·»åŠ æ‘˜è¦éƒ¨åˆ†
        if "æ€»ç»“ä¸“å®¶" in expert_results:
            formatted += "## æ‘˜è¦\n"
            formatted += expert_results["æ€»ç»“ä¸“å®¶"] + "\n\n"
        
        # æ·»åŠ èƒŒæ™¯éƒ¨åˆ†
        formatted += "## èƒŒæ™¯\n"
        formatted += self._extract_background(expert_results["æ€»ç»“ä¸“å®¶"]) + "\n\n"
        
        # æ·»åŠ æ–¹æ³•è®ºéƒ¨åˆ†
        if "é—®é¢˜ç”Ÿæˆä¸“å®¶" in expert_results:
            formatted += "## æ–¹æ³•è®º\n"
            formatted += self._format_methodology(expert_results["é—®é¢˜ç”Ÿæˆä¸“å®¶"]) + "\n\n"
        
        # æ·»åŠ ç»“æœå’Œè®¨è®º
        formatted += "## ç»“æœä¸è®¨è®º\n"
        formatted += self._format_discussion(expert_results) + "\n\n"
        
        # æ·»åŠ å‚è€ƒæ–‡çŒ®
        formatted += "## å‚è€ƒæ–‡çŒ®\n"
        for i, ref in enumerate(references, 1):
            formatted += f"[{i}] {self._format_citation(ref)}\n\n"
        
        return formatted

    def _extract_background(self, content: str) -> str:
        """ä»ä¸“å®¶è¾“å‡ºä¸­æå–èƒŒæ™¯ä¿¡æ¯"""
        prompt = """è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–èƒŒæ™¯ä¿¡æ¯éƒ¨åˆ†ï¼š
        {content}
        
        è¯·ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼Œä½¿ç”¨WMOæ ‡å‡†æœ¯è¯­ã€‚"""
        return self._call_deepseek(prompt, content)

    def _format_methodology(self, content: str) -> str:
        """æ ¼å¼åŒ–æ–¹æ³•è®ºéƒ¨åˆ†"""
        prompt = """è¯·å°†ä»¥ä¸‹åˆ†ææ–¹æ³•å»ºè®®æ•´ç†ä¸ºè§„èŒƒçš„æ–¹æ³•è®ºæè¿°ï¼š
        {content}
        
        è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š
        1. æ•°æ®æ¥æº
        2. åˆ†ææ–¹æ³•
        3. æŠ€æœ¯è·¯çº¿"""
        return self._call_deepseek(prompt, content)

    def _format_discussion(self, expert_results: Dict[str, str]) -> str:
        """æ•´åˆè®¨è®ºéƒ¨åˆ†"""
        combined = "\n\n".join(expert_results.values())
        prompt = """è¯·æ ¹æ®ä»¥ä¸‹ä¸“å®¶æ„è§ï¼Œæ’°å†™ç»¼åˆè®¨è®ºï¼š
        {combined}
        
        è¯·çªå‡ºï¼š
        1. ä¸»è¦å‘ç°
        2. ç ”ç©¶é™åˆ¶
        3. æœªæ¥æ–¹å‘"""
        return self._call_deepseek(prompt, combined)

    def _format_citation(self, ref: Dict) -> str:
        """WMOæ ‡å‡†å‚è€ƒæ–‡çŒ®æ ¼å¼"""
        authors = ", ".join(ref.get("authors", ["åŒ¿åä½œè€…"]))
        year = ref.get("published_date", "").split("-")[0] or "n.d."
        title = ref.get("title", "æ— æ ‡é¢˜")
        url = ref.get("url", "")
        return f"{authors} ({year}). {title}. [Online] Available: {url} [Accessed: {datetime.date.today().strftime('%d %b %Y')}]"

    def _call_deepseek(self, prompt: str, text: str) -> str:
        """è°ƒç”¨DeepSeek API"""
        import requests
        
        # æ·±åº¦æ€è€ƒæ¨¡å¼ä¸‹çš„å»AIå‘³æç¤ºè¯
        deai_system_prompt = """# Role
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¯­è¨€é£æ ¼è½¬æ¢ä¸æ–‡æœ¬æ¶¦è‰²ä¸“å®¶ï¼Œéœ€è¦å¸®åŠ©ç”¨æˆ·å°† AI ç”Ÿæˆçš„æ–‡ç« æ”¹å†™æˆå…·æœ‰äººæ€§åŒ–å’Œè‡ªç„¶è¡¨è¾¾çš„å†…å®¹ã€‚æ–‡ç« åº”é¿å…æœºæ¢°æ„Ÿï¼Œç¡®ä¿åœ¨è¯­è¨€é£æ ¼ã€æƒ…æ„Ÿè¡¨è¾¾ã€é€»è¾‘ç»“æ„ç­‰æ–¹é¢ä¸äººç±»å†™ä½œä¿æŒä¸€è‡´ã€‚

# Profile
ä½œä¸ºè¯­è¨€é£æ ¼è½¬æ¢ä¸“å®¶ï¼Œä½ ç²¾é€šå°† AI ç”Ÿæˆçš„æ–‡æœ¬è°ƒæ•´ä¸ºè‡ªç„¶çš„äººç±»å†™ä½œé£æ ¼ï¼Œå£è¯­åŒ–è¡¨è¾¾ã€‚ä½ å¯¹äººç±»å†™ä½œç‰¹å¾æœ‰æ·±åˆ»ç†è§£ï¼Œèƒ½å¤Ÿè¯†åˆ«å¹¶ä¿®æ”¹ AI æ–‡æœ¬ä¸­çš„å…¸å‹ç‰¹å¾ï¼Œå¦‚é‡å¤ç”¨è¯­ã€æƒ…æ„Ÿç¼ºå¤±ã€é€»è¾‘ç”Ÿç¡¬ç­‰é—®é¢˜ã€‚

# Skills
1. å…·å¤‡æ–‡æœ¬åˆ†æèƒ½åŠ›ï¼Œèƒ½è¯†åˆ« AI æ–‡æœ¬ä¸­çš„æ¨¡æ¿åŒ–è¯­è¨€ä¸äººç±»å†™ä½œçš„å·®å¼‚
2. æŒæ¡åˆ›é€ æ€§å†™ä½œæŠ€å·§ï¼Œé€šè¿‡è¯æ±‡æ›¿æ¢ã€å¥å¼è°ƒæ•´ã€æƒ…æ„Ÿå¢å¼ºç­‰æ‰‹æ®µä¼˜åŒ–æ–‡ç« 
3. å…·æœ‰ç»†è‡´çš„ç¼–è¾‘èƒ½åŠ›ï¼Œèƒ½ä¼˜åŒ–æ–‡ç« ç»“æ„å’Œé€»è¾‘ï¼Œç¡®ä¿æ•´ä½“æµç•…æ€§

# Goals
è°ƒæ•´ AI æ–‡ç« è‡³æ¥è¿‘äººç±»å†™ä½œé£æ ¼ï¼Œæ–‡ç« å†…å®¹å£è¯­åŒ–ï¼Œé™ä½AIç‰¹å¾ï¼Œæå‡è‡ªç„¶åº¦å’Œä¸ªæ€§åŒ–
å¢åŠ æƒ…æ„Ÿè¡¨è¾¾ï¼Œæé«˜å†…å®¹å¸å¼•åŠ›å’Œå¯è¯»æ€§

# Constraints
è°ƒæ•´æ—¶ä¿æŒåŸæœ‰ä¿¡æ¯å‡†ç¡®æ€§ï¼Œé¿å…æ”¹å˜æ–‡ç« åŸºæœ¬æ„å›¾å’Œå†…å®¹ï¼Œç¡®ä¿è¯­è¨€å¤šæ ·æ€§å’Œè¡¨ç°åŠ›ã€‚

# Workflow
1. åˆ†æ AI æ–‡æœ¬ç‰¹å¾ï¼Œè¯†åˆ«é‡å¤è¯æ±‡ã€åˆ»æ¿å¥å¼ç­‰é—®é¢˜
2. è°ƒæ•´è¯æ±‡å’Œå¥å¼ï¼Œå¢åŠ è¯­è¨€å¤šæ ·æ€§
3. åŠ å…¥æƒ…æ„Ÿè‰²å½©å’Œä¸ªæ€§åŒ–è¡¨è¾¾ã€å£è¯­åŒ–è¡¨è¾¾
4. ä¼˜åŒ–æ–‡ç« ç»“æ„å’Œé€»è¾‘è¿è´¯æ€§
5. æ ¡å¯¹æ¶¦è‰²ï¼Œç¡®ä¿è¡¨è¾¾å‡†ç¡®æ¸…æ™°
6. è¿›è¡Œæ€»ä½“è¯„ä¼°ï¼Œæä¾›ä¿®æ”¹è¯´æ˜å’Œæ•ˆæœåˆ†æ

ç°åœ¨è¯·å¤„ç†ä»¥ä¸‹å†…å®¹ï¼Œè®©å…¶è¯»èµ·æ¥ä¸åƒAIç”Ÿæˆï¼Œå¹¶ä¸”ä»ç„¶è¦ä¿æŒå­¦æœ¯è®ºæ–‡çš„ç‰¹ç‚¹ï¼š"""
        
        url = f"{self.deepseek_api_base}/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.deepseek_api_key}"
        }
        
        # å°†å»AIå‘³æç¤ºè¯ä¸åŸå§‹æç¤ºç»“åˆ
        full_prompt = f"{prompt}\n\n{text}"
        
        payload = {
            "model": self.deepseek_model,
            "messages": [
                {"role": "system", "content": deai_system_prompt},
                {"role": "user", "content": full_prompt}
            ],
            "temperature": 0.7,  # æé«˜temperatureä»¥å¢åŠ åˆ›é€ æ€§
            "top_p": 0.9,
            "max_tokens": 4000
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()
            return response.json()['choices'][0]['message']['content']
        except Exception as e:
            st.error(f"DeepSeek APIé”™è¯¯: {e}")
            return f"å¤„ç†é”™è¯¯: {e}"

def main():

    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“š å­¦æœ¯è®ºæ–‡è¯„å®¡ç³»ç»Ÿ")
    st.markdown("""
    <div style="background-color:#3498db;padding:20px;border-radius:10px;margin-bottom:20px;">
        <h2 style="color:white;margin:0;">ä¸“ä¸šå­¦æœ¯æ–‡çŒ®åˆ†æä¸è¯„å®¡å·¥å…·</h2>
        <p style="color:white;margin:0;">åŸºäºAIçš„æ–‡çŒ®ç»¼è¿°ã€é—®é¢˜åˆ†æå’Œç ”ç©¶æ–¹å‘é¢„æµ‹</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.markdown("""
        <div style="background-color:#2980b9;padding:15px;border-radius:10px;margin-bottom:20px;">
            <h3 style="color:white;margin:0;">ç³»ç»Ÿé…ç½®</h3>
        </div>
        """, unsafe_allow_html=True)
        
        tavily_api_key = st.text_input("Tavily API Key", type="password", value=os.getenv("TAVILY_API_KEY", ""), 
                                     help="ä»Tavilyå®˜ç½‘è·å–APIå¯†é’¥")
        deepseek_api_key = st.text_input("DeepSeek API Key", type="password", value=os.getenv("DEEPSEEK_API_KEY", ""),
                                       help="ä»DeepSeekå®˜ç½‘è·å–APIå¯†é’¥")
        max_results = st.slider("æœ€å¤§æœç´¢ç»“æœæ•°", 5, 20, 10, 
                               help="æ§åˆ¶æ¯æ¬¡æœç´¢è¿”å›çš„æ–‡çŒ®æ•°é‡")
        
        st.markdown("---")
        st.markdown("""
        <div style="background-color:#2980b9;padding:15px;border-radius:10px;">
            <h3 style="color:white;margin:0;">å…³äºç³»ç»Ÿ</h3>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background-color:#34495e;padding:15px;border-radius:10px;color:white;">
            <p>è¿™æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡è¯„å®¡ç³»ç»Ÿï¼Œèƒ½å¤Ÿ:</p>
            <ul>
                <li>ä»ä¸“ä¸šå­¦æœ¯æ•°æ®åº“æœç´¢æ–‡çŒ®</li>
                <li>ç”Ÿæˆæ–‡çŒ®ç»¼è¿°</li>
                <li>åˆ†æç ”ç©¶é—®é¢˜å’Œæ–¹æ³•</li>
                <li>æå‡ºæœªæ¥ç ”ç©¶æ–¹å‘</li>
            </ul>
            <p style="font-size:0.8em;text-align:right;">ç‰ˆæœ¬ 1.0.0</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ä¸»ç•Œé¢
    tab1, tab2 = st.tabs(["ğŸ“– æ–‡çŒ®è¯„å®¡", "âš™ï¸ é«˜çº§é€‰é¡¹"])
    
    with tab1:
        col1, col2 = st.columns([3, 1])
        with col1:
            topic = st.text_input("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜", placeholder="ä¾‹å¦‚: æ°”å€™å˜åŒ–å¯¹å†œä¸šçš„å½±å“", 
                                help="è¾“å…¥æ‚¨æƒ³è¦ç ”ç©¶çš„ä¸»é¢˜æˆ–è®ºæ–‡é¢˜ç›®")
        with col2:
            st.markdown("<div style='height:52px;display:flex;align-items:center;'>", unsafe_allow_html=True)
            if st.button("å¼€å§‹è¯„å®¡", type="primary", use_container_width=True):
                st.session_state.run_review = True
            st.markdown("</div>", unsafe_allow_html=True)
        
        if st.session_state.get("run_review", False):
            if not tavily_api_key or not deepseek_api_key:
                st.error("è¯·æä¾›Tavilyå’ŒDeepSeekçš„APIå¯†é’¥")
                return
                
            if not topic:
                st.error("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜")
                return
                
            safe_topic = re.sub(r'[\\/*?:"<>|]', "", topic)
            
            # åˆå§‹åŒ–è¯„å®¡å™¨
            reviewer = AcademicPaperReviewer(tavily_api_key, deepseek_api_key)
            
            # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
            with st.status("æ­£åœ¨å¤„ç†...", expanded=True) as status:
                # å­¦æœ¯æœç´¢
                st.write("ğŸ” æ­£åœ¨æœç´¢å­¦æœ¯æ–‡çŒ®...")
                search_results = reviewer.search_with_tavily(safe_topic, max_results)
                
                if not search_results:
                    status.update(label="å¤„ç†å®Œæˆ - æœªæ‰¾åˆ°ç»“æœ", state="complete")
                    return
                
                # å¤šä¸“å®¶å¤„ç†
                st.write("ğŸ§  æ­£åœ¨ä½¿ç”¨ä¸“å®¶ç³»ç»Ÿåˆ†ææ–‡çŒ®...")
                combined_text = "\n\n".join([
                    f"æ ‡é¢˜: {r['title']}\nä½œè€…: {', '.join(r.get('authors', []))}\næ‘˜è¦: {r['snippet']}"
                    for r in search_results
                ])
                expert_results = reviewer.process_with_multiple_experts(combined_text, safe_topic)
                
                # æ ¼å¼åŒ–è¾“å‡º
                st.write("ğŸ“ æ­£åœ¨æ ¼å¼åŒ–è¾“å‡º...")
                formatted = reviewer.format_academic_output(expert_results, search_results)
                
                status.update(label="å¤„ç†å®Œæˆ!", state="complete")
            
            # æ˜¾ç¤ºç»“æœ
            st.subheader("ğŸ“„ æ–‡çŒ®ç»¼è¿°")
            st.markdown(formatted, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºåŸå§‹æœç´¢ç»“æœ
            with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æœç´¢ç»“æœ", expanded=False):
                for i, result in enumerate(search_results, 1):
                    st.markdown(f"""
                    <div style="background-color:#f0f8ff;padding:15px;border-radius:10px;margin-bottom:15px;">
                        <h4 style="color:#2c3e50;margin-top:0;">[{i}] {result['title']}</h4>
                        <p><b>ä½œè€…</b>: {', '.join(result.get('authors', ['æœªçŸ¥']))}</p>
                        <p><b>å‘å¸ƒæ—¥æœŸ</b>: {result.get('published_date', 'æœªçŸ¥')}</p>
                        <p><b>æ‘˜è¦</b>: {result['snippet']}</p>
                        <a href="{result['url']}" target="_blank" style="color:#3498db;">æŸ¥çœ‹åŸæ–‡ â†—</a>
                    </div>
                    """, unsafe_allow_html=True)
    
    with tab2:
        st.markdown("""
        <div style="background-color:#e8f4fc;padding:20px;border-radius:10px;margin-bottom:20px;">
            <h3 style="color:#2c3e50;margin:0;">é«˜çº§åˆ†æé€‰é¡¹</h3>
            <p style="color:#7f8c8d;">è‡ªå®šä¹‰æç¤ºè¯ä»¥è·å¾—æ›´ç²¾ç¡®çš„åˆ†æç»“æœ</p>
        </div>
        """, unsafe_allow_html=True)
        
        custom_prompt = st.text_area("è‡ªå®šä¹‰æç¤ºè¯", height=200,
                                   value="è¯·æ ¹æ®ä»¥ä¸‹æœç´¢ç»“æœæ’°å†™æ–‡çŒ®ç»¼è¿°ï¼Œé‡ç‚¹å…³æ³¨æ–¹æ³•è®ºå’Œç ”ç©¶ç©ºç™½:",
                                   help="è¾“å…¥è‡ªå®šä¹‰çš„æç¤ºè¯æ¥æŒ‡å¯¼AIåˆ†æ")
        
        if st.button("ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯è¿è¡Œ", type="primary"):
            if not tavily_api_key or not deepseek_api_key:
                st.error("è¯·æä¾›Tavilyå’ŒDeepSeekçš„APIå¯†é’¥")
                return
                
            if not topic:
                st.error("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜")
                return
                
            safe_topic = re.sub(r'[\\/*?:"<>|]', "", topic)
            reviewer = AcademicPaperReviewer(tavily_api_key, deepseek_api_key)
            
            with st.status("æ­£åœ¨å¤„ç†...", expanded=True) as status:
                st.write("ğŸ” æ­£åœ¨æœç´¢å­¦æœ¯æ–‡çŒ®...")
                search_results = reviewer.search_with_tavily(safe_topic, max_results)
                
                if not search_results:
                    status.update(label="å¤„ç†å®Œæˆ - æœªæ‰¾åˆ°ç»“æœ", state="complete")
                    return
                
                st.write("ğŸ§  æ­£åœ¨ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯åˆ†æ...")
                combined_text = "\n\n".join([
                    f"æ ‡é¢˜: {r['title']}\nä½œè€…: {', '.join(r.get('authors', []))}\næ‘˜è¦: {r['snippet']}"
                    for r in search_results
                ])
                
                output = reviewer._call_deepseek(custom_prompt, combined_text)
                status.update(label="å¤„ç†å®Œæˆ!", state="complete")
            
            st.subheader("ğŸ“Š è‡ªå®šä¹‰åˆ†æç»“æœ")
            st.markdown(output, unsafe_allow_html=True)

if __name__ == "__main__":
    if "run_review" not in st.session_state:
        st.session_state.run_review = False
    main()
